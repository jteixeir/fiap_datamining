table(cut(pluv, breaks = pretty(pluv, n = 4)))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))))
table(cut(pluv, breaks = pretty(pluv, n = 2)))
table(cut(pluv, breaks = pretty(pluv, n = 3)))
table(cut(pluv, breaks = pretty(pluv, n = 7)))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
summary(pluv)
transform(table(cut(pluv, breaks = pretty(pluv, n = 6))))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))))
table(cut(pluv, breaks = pretty(pluv, n = 4)))
table(cut(pluv, breaks = pretty(pluv, n = 4),right = FALSE))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv2, breaks = pretty(pluv2, n = 4))))
pluv2 = c(110, 100, 60, 80, 70, 18, 17, 0, 42, 89, 108, 143)
transform(table(cut(pluv2, breaks = pretty(pluv2, n = 4))))
transform(table(cut(pluv2, breaks = pretty(pluv2, n = 4), include.lowest = TRUE)))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))))
transform(table(cut(pluv, breaks = c(0,40,80,120,160))))
hist(pluv, breaks = 4)
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = c(0,40,80,120,160))))
hist(pluv, breaks = c(0,40,80,120,160))
mean(pluv)
sd(pluv)
var(pluv)
median(pluv)
hist(pluv, breaks = 4)
hist(pluv, breaks = 4)
hist(pluv, breaks = 5)
hist(pluv, breaks = c(0,40,80,120,160))
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = pretty(pluv, n = 5))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = pretty(pluv, n = 2))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
summary(pluv)
table(pluv)
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = c(0,40,80,120,160))))
transform(table(cut(pluv, breaks = c(17,40,80,120,160))))
hist(pluv, breaks = 5)
hist(pluv, breaks = c(0,40,80,120,160))
pie(table(cut(pluv, breaks = c(0,40,80,120,160))))
mean(pluv)
sd(pluv)
var(pluv)
median(pluv)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
summary(pluv)
transform(table(cut(pluv, breaks = c(17,40,80,120,160))))
hist(pluv, breaks = 5)
hist(pluv, breaks = c(0,40,80,120,160))
pie(table(cut(pluv, breaks = c(0,40,80,120,160))))
mean(pluv)
sd(pluv)
var(pluv)
median(pluv)
#0. TEMA: A QUALIDADE DE VIDA DO BRASILEIRO, NA PERSPECTIVA SOCIAL, MELHOROU SUBSTANCIALMENTE SE COMPARADO
#         O ANO DE 2015 COM O ANO DE 2005
#1. PERGUNTA 1: QUAL É A DIFERENÇA DE DISTRIBUIÇÃO POPULACIONAL POR FAIXA DE IDADE ENTRE 2005 E 2015
#1. DISTRIBUIÇÃO POPULACIONAL 2005
distribuicao2005UrbanaTotal<-c(11667,13585,13645,14407,14624,13172,11743,11171,10574,9348,7777,5992,4622,3721,6791)
distribuicao2005UrbanaHomens<-c(5899,6942,6931,7183,7225,6328,5645,5226,4991,4313,3625,2746,2058,1627,2686)
distribuicao2005UrbanaMulheres<-c(5768,6642,6713,7224,7398,6844,6098,5946,5583,5035,4152,3247,2564,2095,4105)
distribuicao2005RuralTotal<-c(2999,3435,3571,3347,2715,2310,2128,2006,1869,1593,1389,1258,972,770,1338)
distribuicao2005RuralHomens<-c(1488,1746,1868,1786,1453,1203,1097,1028,991,843,712,662,527,402,689)
distribuicao2005RuralMulheres<-c(1510,1689,1703,1562,1262,1107,1031,978,878,750,677,596,446,368,649)
#1 DISTRIBUIÇÃO POPULACIONAL 2015
distribuicao2015UrbanaTotal<-c(10901,11680,12841,14523,13518,13181,14087,13500,12500,11614,11131,9341,7761,6089,10900)
distribuicao2015UrbanaHomens<-c(5580,5963,6537,7304,6835,6477,6757,6398,5919,5433,5112,4213,3410,2663,4456)
distribuicao2015UrbanaMulheres<-c(5321,5717,6304,7219,6683,6704,7330,7102,6581,6182,6019,5128,4350,3426,6443)
distribuicao2015RuralTotal<-c(2041,2582,3023,2956,2073,2095,2194,2258,2036,1993,1857,1561,1402,1115,2108)
distribuicao2015RuralHomens<-c(1050,1326,1566,1607,1121,1050,1142,1166,1062,1059,961,826,716,604,1095)
distribuicao2015RuralMulheres<-c(991,1256,1457,1349,953,1045,1052,1092,974,934,897,735,686,511,1012)
#1. AGRUPAMENTO DA DISTRIBUIÇÃO POPULACIONAL
distribuicaoUrbanaAgrupamento<-c('0 a 4 anos','5 a 9 anos','10 a 14 anos','15 a 19 anos','20 a 24 anos','25 a 29 anos','30 a 34 anos','35 a 39 anos','40 a 44 anos','45 a 49 anos','50 a 54 anos','55 a 59 anos','60 a 64 anos','65 a 69 anos','70 anos ou mais')
#barplot(distribuicao2005RuralTotal
#        , names.arg = distribuicaoUrbanaAgrupamento
#        , main='Distribuição da população rural 2005'
#        , xlab='Faixa etária'
#        , ylab='Número de habitantes')
#barplot(distribuicao2015RuralTotal
#        , names.arg = distribuicaoUrbanaAgrupamento
#        , main='Distribuição da população rural 2015'
#        , xlab='Faixa etária'
#        , ylab='Número de habitantes')
plot(distribuicao2005RuralTotal
, ylim=c(0,15000)
, xlab = 'Faixa etária'
, ylab = 'Habitantes'
, main ='Distribuição populacional 2005 x 2015 - Rural x Urbana'
, axes = FALSE)
points(distribuicao2015RuralTotal, col='2')
points(distribuicao2005UrbanaTotal, col='3')
points(distribuicao2015UrbanaTotal, col='4')
axis(1, at=1:15, lab=distribuicaoUrbanaAgrupamento)
legend('topright'
, range(0, distribuicao2005UrbanaTotal, distribuicao2015UrbanaTotal)[2]
, c('Rural 2005', 'Rural 2015', 'Urbana 2005', 'Urbana 2015')
, cex=0.8
, col=c('1','2','3','4')
, lty=1:1)
legend('topright'
, range(0, distribuicao2005UrbanaTotal, distribuicao2015UrbanaTotal)[2]
, c('Rural 2005', 'Rural 2015', 'Urbana 2005', 'Urbana 2015')
, cex=0.8
, col=c('1','2','3','4')
, lty=1:1)
#1. CONCLUSÃO:  TANTO NA DISTRIBUIÇÃO POPULACIONAL URBANA QUANTO NA RURAL, A FAIXA DE IDADE MENOR QUE 25 ANOS
#               SOFRE UMA REDUÇÃO DE DISTRIBUIÇÃO, ENQUANTO QUE ACIMA DE 29 ANOS AUMENTOU.
#               ISSO INDICA QUE EM 2015 HÁ UMA MENOR TAXA DE NATALIDADE, LOGO AS PESSOAS TEM MENOS GASTOS COM FILHOS
#               E ASSIM USANDO A RENDA PARA OUTROS ASPECTOS QUE MELHORAM SUA QUALIDADE DE VIDA
#2. HÁ CORRELAÇÃO NO EQUILÍBRIO POPULACIONAL RURAL E URBANO?
cor(distribuicao2005UrbanaTotal, distribuicao2005RuralTotal)
cor(distribuicao2015UrbanaTotal, distribuicao2015RuralTotal)
legend('topright'
, range(0, distribuicao2005UrbanaTotal, distribuicao2015UrbanaTotal)[2]
, c('Rural 2005', 'Rural 2015', 'Urbana 2005', 'Urbana 2015')
, cex=0.8
, col=c('1','2','3','4')
, lty=1:1)
#1. CONCLUSÃO:  TANTO NA DISTRIBUIÇÃO POPULACIONAL URBANA QUANTO NA RURAL, A FAIXA DE IDADE MENOR QUE 25 ANOS
#               SOFRE UMA REDUÇÃO DE DISTRIBUIÇÃO, ENQUANTO QUE ACIMA DE 29 ANOS AUMENTOU.
#               ISSO INDICA QUE EM 2015 HÁ UMA MENOR TAXA DE NATALIDADE, LOGO AS PESSOAS TEM MENOS GASTOS COM FILHOS
#               E ASSIM USANDO A RENDA PARA OUTROS ASPECTOS QUE MELHORAM SUA QUALIDADE DE VIDA
#2. HÁ CORRELAÇÃO NO EQUILÍBRIO POPULACIONAL RURAL E URBANO?
cor(distribuicao2005UrbanaTotal, distribuicao2005RuralTotal)
cor(distribuicao2015UrbanaTotal, distribuicao2015RuralTotal)
#2. CONSLUSÃO:  HÁ UMA CORRELAÇÃO FORTE ENTRE O A DISTRIBUIÇÃO POPULACIONAL URBANA E RURAL EM 2005 E 2015, SENDO QUE
#               ESSA CORRELAÇÃO PERDE FORÇA EM 2015
#3. A TAXA DE CRESCIMETNO POPULACIONAL BRASILEIRA DE 2005 ATÉ 2015?
populacao2012 = 199.336
populacao2013 = 201.109
populacao2014 = 202.82
populacao2015 = 204.490
taxaCrescimentoPopulacao_2013_2012 = populacao2013 - populacao2012
taxaCrescimentoPopulacao_2014_2013 = populacao2014 - populacao2013
taxaCrescimentoPopulacao_2015_2014 = populacao2015 - populacao2014
taxaCrescimentoPopulacional<-c(taxaCrescimentoPopulacao_2013_2012,taxaCrescimentoPopulacao_2014_2013, taxaCrescimentoPopulacao_2015_2014)
plot(taxaCrescimentoPopulacional
, type='l'
, xlab = 'Ano'
, ylab = 'Taxa de crescimento'
, main ='Taxa de crescimento população 2012 - 2015'
, axes = FALSE)
axis(1, at=1:3, lab=c('2012 - 2013', '2013 - 2014', '2014 - 2015'))
axis(2, at=1:3, lab=taxaCrescimentoPopulacional)
#3. CONSLUSÃO:  A TAXA DE CRESCIMENTO CAI ANO A ANO FORTALECENDO A CONCLUSÃO
#   DO ITEM 2.
#4. A RENDA DE 2015 É MAIOR EM RELAÇÃO A 2005? NESSE CASO NÃO IREMOS DIVIDIR
#   ENTRE RURAL E URBANO POR CONTA DA CORRELAÇÃO
#   ENTRE OS DOIS SER FORTE
renda2005<-c(11989,26297,29704,11179,10476,6837,2586,1025,51633,1189)
renda2015<-c(12047,31671,42692,15105,10797,6956,2407,708,37472,1937)
labelsRenda<-c('Até 1/2'
,'Mais de 1/2 a 1'
,'Mais de 1 a 2'
,'Mais de 2 a 3'
,'Mais de 3 a 5'
,'Mais de 5 a 10'
,'Mais de 10 a 20'
,'Mais de 20'
,'Sem rendimento (2)'
,'Sem declaração')
barplot(renda2005
, las = 2, cex.names = .7
, names.arg = labelsRenda)
barplot(renda2015
, las = 2, cex.names = .7
, names.arg = labelsRenda)
diferencaRenda_2015_2005<-renda2015 - renda2005
barplot(diferencaRenda_2015_2005
, las = 2, cex.names = .7
, names.arg = labelsRenda
, main = 'Diferença de rendimento salário mínimo (2015 - 2005)'
, ylab = 'Pessoas'
, xlab = 'Faixa salário mínimo')
#4. CONCLUSÃO:  HÁ MAIS PESSOAS COM RENDIMENTO EM 2015 COM RELAÇÃO A 2005
dados = c(903.88, 1036.92, 1098.04, 1011.26, 1020.7, 915.38, 1014.53, 1097.79,
934.52, 1214.08, 993.45, 1120.19, 860.41, 1039.19, 950.38, 941.83, 936.78,
1086.98, 1144.94, 1066.12)
t.test(dados, mu = 1055)
maq1 <- c(16.6, 13.4, 14.5, 15.1, 12.9, 15.2, 14.0, 16.6, 15.4, 13.0)
maq2 <- c( 15.8, 17.9, 18.2, 20.2, 18.1, 17.8, 18.3, 18.6, 17.0, 18.4)
t.test(maq1, maq2, alternative = "two.sided")
maq1 <- c(16.6, 13.4, 14.6, 15.1, 12.9, 15.2, 14.0, 16.6, 15.4, 13.0)
maq2 <- c( 15.8, 17.9, 18.2, 20.2, 18.1, 17.8, 18.3, 18.6, 17.0, 18.4)
t.test(maq1, maq2, alternative = "two.sided")
t.test(maq1, maq2, alternative = "less")
t.test(maq1, maq2, alternative = "greater")
evento1 <- c(254.29, 165, 189,02, 277.46, 235.56, 198.32)
t.test(evento1, mu=285)
t.test(evento1, mu=285, alternative = "two.sided")
t.test(evento1, mu=285, alternative = "two.sided", conf.level = 0.99)
evento1 <- c(254.29, 165, 189,02, 277.46, 235.56, 198.32)
t.test(evento1, mu=285, alternative = "two.sided", conf.level = 0.99)
evento1 <- c(254.29, 165, 189.02, 277.46, 235.56, 198.32)
t.test(evento1, mu=285, alternative = "two.sided", conf.level = 0.99)
irmãos = c(0,1,2,0,0,2,4,1,2,3,2,1,1,1,1,0,0,0,1,2,3,4,2,2,1,1,0,1,0,1,0,1,0,1,0,2,1,1,2,0,1,1)
t.test(irmãos, m = 2 )
irmãos = c(0,1,2,0,0,2,4,1,2,3,2,1,1,1,1,0,0,0,1,2,3,4,2,2,1,1,0,1,0,1,0,1,0,2,1,1,2,0,1,1)
t.test(irmãos, m = 2 )
t.test(pluv, mu = 70.6)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
t.test(pluv, mu = 70.6)
t.test(pluv, mu = 70.6, alternative = "less")
t.test(pluv, mu = 70.6, alternative = "greater")
t.test(irmãos, m = 2)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
t.test(pluv, mu = 70.6)
t.test(pluv, mu = 70.6, alternative = "less")
t.test(pluv, mu = 70.6, alternative = "greater")
t.test(pluv, mu = 70.6)
evento1 <- c(254.29, 165, 189.02, 277.46, 235.56, 198.32)
t.test(evento1, mu=285, alternative = "two.sided", conf.level = 0.99)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
t.test(pluv, mu = 70.6)
t.test(evento1, mu=285, alternative = "two.sided", conf.level = 0.99)
t.test(pluv, mu=285, alternative = "two.sided", conf.level = 0.99)
irmãos = c(0,1,2,0,0,2,4,1,2,3,2,1,1,1,1,0,0,0,1,2,3,4,2,2,1,1,0,1,0,1,0,1,0,2,1,1,2,0,1,1)
t.test(irmãos, mu=2, alternative = "two.sided", conf.level = 0.99)
t.test(irmãos, mu = 70.6, alternative = "greater")
t.test(irmãos, mu = 70.6, alternative = "less")
install.packages("igraph")
install.packages("plyr")
install.packages("rgexf")
install.packages("rgexf")
install.packages("igraph")
install.packages("network")
install.packages("plyr")
install.packages("latticeExtra")
install.packages("XML")
install.packages("scales")
install.packages("forecast")
install.packages("zoo")
install.packages("ggplot2")
install.packages("plotly")
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
summary(pluv)
table(pluv)
transform(table(cut(pibpcap, breaks = pretty(pibpcap, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = pretty(pibpcap, n = 4))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = pretty(pibpcap, n = 2))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = pretty(pluv, n = 2))),FreqRel = Freq/12, FreqAcum = cumsum(Freq), FreqRelAcum = cumsum(Freq)/12)
transform(table(cut(pluv, breaks = c(17,40,80,120,160))))
hist(pluv, breaks = 5)
hist(pluv, breaks = c(0,40,80,120,160))
pie(table(cut(pluv, breaks = c(0,40,80,120,160))))
mean(pluv)
sd(pluv)
median(pluv)
t.test(pluv, mu = 70.6)
alt = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
summary(pluv)
table(pluv)
transform(table(cut(pluv, breaks = c(17,40,80,120,160))))
hist(pluv, breaks = 5)
hist(pluv, breaks = c(0,40,80,120,160))
mean(pluv)
sd(pluv)
var(pluv)
median(pluv)
t.test(pluv, mu = 70.6)
.
t.test(pluv, mu = 70.6)
t.test(pluv, mu = 71)
t.test(pluv, mu = 100)
t.test(pluv, mu = 70)
t.test(pluv, mu = 71)
t.test(pluv, mu = 100)
alt = c(165, 174, 177, 177, 180, 171, 170, 178, 171, 162, 182, 171, 172, 174, 190, 160, 202, 191, 174, 183, 180, 175)
summary(pluv)
summary(alt)
table(pluv)
table(alt)
t.test(alt, mu = 175)
t.test(alt, mu = 160)
t.test(alt, mu = 176.3)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
t.test(pluv, mu = 176.3)
t.test(pluv, mu = 100)
t.test(pluv, mu = 176)
t.test(pluv, mu = 100)
t.test(pluv, mu = 100)
alt = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
summary(alt)
table(alt)
table(alt)
table(alt)
summary(alt)
t.test(pluv, mu = 70.6, alternative = "less")
t.test(alt, mu = 70.6, alternative = "less")
t.test(pluv, mu = 70.6, alternative = "greater")
t.test(alt, mu = 70.6, alternative = "greater")
t.test(evento1, mu=285, alternative = "two.sided", conf.level = 0.99)
t.test(alt, mu=285, alternative = "two.sided", conf.level = 0.99)
t.test(alt, mu = 285)
t.test(alt, mu=285, alternative = "two.sided", conf.level = 0.95)
alt = c(165, 174, 177, 177, 180, 171, 170, 178, 171, 162, 182, 171, 172, 174, 190, 160, 202, 191, 174, 183, 180, 175)
t.test(alt, mu = 175)
t.test(alt, mu = 175, alternative = "less")
otes a serem utilizados neste post
library(dplyr)
library(readr)
library(rpart)
library(rpart.plot)
library(xtable)
install.packages("dplyr")
install.packages("readr")
install.packages("rpart")
install.packages("repart.plot")
install.packages("xtable")
otes a serem utilizados neste post
library(dplyr)
library(readr)
library(rpart)
library(rpart.plot)
library(xtable)
install.packages("dplyr")
# Pacotes a serem utilizados neste post
library(dplyr)
library(readr)
library(rpart)
library(rpart.plot)
library(xtable)
# Lendo os dados do titanic a partir de repositório, selecionando e tratando variáveis
titanic <- "https://gitlab.com/dados/open/raw/master/titanic.csv" %>%
# Lendo os dados do titanic a partir de repositório, selecionando e tratando variáveis
titanic <- "https://gitlab.com/dados/open/raw/master/titanic.csv" %>%
read_csv %>%
select(survived, embarked, sex,
sibsp, parch, fare) %>%
mutate(
survived = as.factor(survived),
embarked = as.factor(embarked),
sex = as.factor(sex))
# Mostrando o head dos dados
print(xtable(head(titanic)), type = "html", digits = 2, include.rownames=FALSE)
titanic <- "https://gitlab.com/dados/open/raw/master/titanic.csv" %>%
read_csv %>%
select(survived, embarked, sex,
sibsp, parch, fare) %>%
mutate(
survived = as.factor(survived),
embarked = as.factor(embarked),
sex = as.factor(sex))
# Mostrando o head dos dados
print(xtable(head(titanic)), type = "html", digits = 2, include.rownames=FALSE)
# Separar os dados em treino e teste
set.seed(100)
.data <- c("training", "test") %>%
sample(nrow(titanic), replace = T) %>%
split(titanic, .)
# Criar a árvore de decisão
rtree_fit <- rpart(survived ~ .,
.data$training
)
rtree_fit <- rpart(survived ~ .,
.data$training
)
rpart.plot(rtree_fit)
alt <- c(14, 29, 6, 25, 18, 4, 18, 12, 22, 6, 30, 11, 30, 5, 20,
13, 9, 32, 24, 13, 19, 4, 28, 14, 29)
resp <- c(0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,
1, 0, 0, 1, 1, 1)
ave <- glm(resp ~ alt,family=binomial)
summary(ave)
plot(alt,resp,xlab="Altura das árvores (vezes 10)",
ylab="Presença de ave(0 e 1) e prob encontro de ave
(curva)")
curve((exp(?3.0597 + 0.1615*x))  / (1+(exp(?3.0597 +
0.1615*x))),add=TRUE)
plot(alt,resp,xlab="Altura das árvores (vezes 10)",
ylab="Presença de ave(0 e 1) e prob encontro de ave
(curva)")
curve((exp(-3.0597 + 0.1615*x)) / (1+(exp(-3.0597 +
0.1615*x))),add=TRUE)
#obtendo o valor do p-value
valor.p1<-2*(1-pt(tcalc1,df=n1-1))
#criando o vetor de dados
x1<- c(12,15,15,14,14)
#definindo o valor da H zero
mu<-12
#obtendo a média dos dados
m1<-mean(x1)
#obtendo o desvio padrão dos dados
sd1<-sd(x1)
#criando o vetor de dados
x1<- c(12,15,15,14,14)
#definindo o valor da H zero
mu<-12
#obtendo a média dos dados
m1<-mean(x1)
#obtendo o desvio padrão dos dados
sd1<-sd(x1)
#obtendo o tamanho da amostra
n1<-length(x1)
#obtendo o valor da estatística do teste
tcalc1<-(m1-mu)/(sd1/sqrt(n1))
#obtendo o valor do p-value
valor.p1<-2*(1-pt(tcalc1,df=n1-1))
#obtendo o valor do t tabelado
ttab<-qt(.975,df=n1-1)
#obtendo o valor do p-value
valor.p1<-2*(1-pt(tcalc1,df=n1-1))
#obtendo o valor do t tabelado
ttab<-qt(.975,df=n1-1)
t.test(x1,mu=12,alternative="two.sided")
t.test(x1,mu=12,alternative="greater")
maq1 <- c(16.6, 13.4, 14.6, 15.1, 12.9, 15.2, 14.0, 16.6, 15.4, 13.0)
maq2 <- c( 15.8, 17.9, 18.2, 20.2, 18.1, 17.8, 18.3, 18.6, 17.0, 18.4)
t.test(maq1, maq2, alternative = "two.sided")
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
t.test(pluv, mu = 70.6)
t.test(pluv, mu= 70.6, alternative = "two.sided", conf.level = 0.99)
t.test(pluv, mu = 71,2)
t.test(pluv, mu = 71.2)
t.test(pluv, mu = 100)
y <- c(10)
X1 <- c(44000)
x2 <- c(540)
x3 <- c(39)
reg <- (lm (y ~ x1 + x2 + x3))
reg <- (lm (y ~ x1 + x2 + x3))
lm (y ~ x1+x2+x3)
X1 <- c(44000)
x1
X <- c(44000)
x
X <- c(44000)
x
t.test(pluv, mu = 70.6, alternative = "less")
irmaos = c(0,1,2,0,0,2,4,1,2,3,2,1,1,1,1,0,0,0,1,2,3,4,2,2,1,1,0,1,0,1,0,1,0,2,1,1,2,0,1,1)
t.test(irmaos, mu < 2)
t.test(irmaos, mu = 2)
pluv = c(110, 100, 60, 80, 70, 18, 17, 17, 42, 89, 108, 143)
summary(pluv)
table(pluv)
transform(table(pluv))
transform(table(pluv), FreqRel = Freq/40)
table(pluv)
table(cut(pluv, breaks = pretty(pluv, n = 4)))
transform(table(cut(pluv, breaks = pretty(pluv, n = 4))))
t.test(pluv, mu = 100)
t.test(pluv, mu = 70)
t.test(pluv, mu = 70.6, alternative = "less")
t.test(pluv, mu = 70.6, alternative = "greater")
t.test(pluv, mu= 70.6, alternative = "two.sided", conf.level = 0.95)
dtm2 <- removeSparseTerms(dtm, sparse = 0.70)
m2 <- as.matrix(dtm2)
# cluster terms
distMatrix <- dist(scale(m2))
fit <- hclust(distMatrix, method = "ward.D")
plot(fit)
rect.hclust(fit, k = 6)
library(tm)
library(NLP)
library(qdap) # Quantitative discourse analysis of transcripts.
library(qdapDictionaries)
library(dplyr) # Data wrangling, pipe operator %>%().
library(RColorBrewer) # Generate palette of colours for plots.
library(ggplot2) # Plot word frequencies.
library(scales) # Include commas in numbers.
library(wordcloud)
library(dplyr)
library(stringr)
rm(list = ls())
ls()
getwd()
setwd("D:/TM5")
cps <- Corpus(DirSource('D:/TM5',
encoding = "UTF-8"),
readerControl = list(language = "pt"))
cps <- tm_map(cps, stripWhitespace)
cps <- tm_map(cps, content_transformer(tolower))
cps <- tm_map(cps, removeWords, stopwords("portuguese"))
#cps <- tm_map(cps, stemDocument)
cps <- tm_map(cps, removeNumbers)
cps <- tm_map(cps, removePunctuation)
cps <- tm_map(cps, removeWords, c("falo", "galeno", "senhor","proqu","a","A","agora","ainda","pra","tÃ¡","dÃ¡","lÃ¡","tÃ´","nÃ©",
"algum","alguma","algumas","alguns","antes","senhora","quatro","aqui","aÃ","conta", "faz", "hoje",
"ao","Ao","aos","aqui","as","se","As","assim","Assim","bem","zero", "vinte", "dia", "coisa", "coisas",
"das","dava","de","dela","dele","dentro","dizer", "dizia", "do","muita", "venha", "entrar", "opinião",
"dos", "dous","e","E","ela","ele","eles","isso","isto","la","em","Em","ter", "ano","liga","longo","lógico",
"fora","fosse","gente","lhe","lo","logo","mais","mas","Mas","me","como","muitas","quais","tantas","tatiana",
"meus","mim","na","pelo", "Pois", "por", "este","diz","então",  "expndexpndtwkerning", "vagas","vezes","lado",
"nas","nem","no","No","nos","nossa","o","com", "é", "cielo" , "expandedcolortblcssrgbccccssrgbccc","têm","nisso",
"O", "os", "Os", "ou","para", "pela", "D", "aí", "né", "vou", "cento","robfs","servieo","toda","todo","todos","tudo",
"que","Que","queria","se","Se","sem","da", "r", "tá", "colortblredgreenblueredgreenblueredgreenblue","deftab","meo","neo",
"senhor","senhora","seu","seus","si","sua","tal", "helveticaneue","ffs", "helveticaneue" , "cocoatextscalingcocoaplatformfonttblffnilfcharset",
"paperwpaperhmarglmargrviewwviewhviewkind","pardpardeftabslpartightenfactor","rtfansiansicpgcocoartf","enteo","cartfes","inteligeancia",
"obstrued","substitued",
"ve","sf","cb","cf",
"inteligeancia","robf","entanto","cor",
"tanto", "tarde","doi","veio", "vi", "vai"))
##################################
dtm <- DocumentTermMatrix(cps)
freq <- sort(colSums(as.matrix(dtm)), decreasing = TRUE)
ord <- order(freq)
parse terms
dtm2 <- removeSparseTerms(dtm, sparse = 0.70)
m2 <- as.matrix(dtm2)
# cluster terms
distMatrix <- dist(scale(m2))
fit <- hclust(distMatrix, method = "ward.D")
plot(fit)
rect.hclust(fit, k = 6) # mode
